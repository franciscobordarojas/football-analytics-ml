{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a8a099-7403-45b6-a462-45e7e31c6781",
   "metadata": {},
   "source": [
    "# Football Analytics & Machine Learning\n",
    "\n",
    "Proyecto de análisis de fútbol aplicando **clustering**, **clasificación** y **recomendación** de jugadores a partir de estadísticas de rendimiento (FBRef) e información de mercado (Transfermarkt).\n",
    "\n",
    "> Nota: esta notebook es una versión “portfolio-ready” del trabajo original. Se prioriza claridad, reproducibilidad y resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fbfa8",
   "metadata": {},
   "source": [
    "## Cómo ejecutar\n",
    "\n",
    "1. Instalar dependencias (ver `requirements.txt` en el repositorio).\n",
    "2. Abrir esta notebook y ejecutar las celdas en orden.\n",
    "3. Asegurarse de contar con los archivos de datos en la carpeta indicada en la sección **Datos**.\n",
    "\n",
    "## Datos\n",
    "\n",
    "- **FBRef**: estadísticas de rendimiento por jugador/temporada.\n",
    "- **Transfermarkt**: información de valor de mercado por jugador.\n",
    "\n",
    "Los datasets se integran mediante identificadores/nombres normalizados (según disponibilidad), y se aplican filtros mínimos (por ejemplo, minutos jugados) para evitar observaciones poco representativas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e42b1-5241-4497-8686-bb3e8647084c",
   "metadata": {},
   "source": [
    "## Francisco Borda Rojas - Julio 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d14df0-18c7-4902-a87c-0e0e52b86492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from formulaic import Formula\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tf_regressor import train_test_split_scale_center\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0a30a-230c-4139-94c5-cfc4e3ad1540",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfed51f-c001-4b51-a5ef-6fae7d87bf49",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3761e",
   "metadata": {},
   "source": [
    "Cargamos el archivo \"FBref2020-21.csv\" en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3749fd-452d-42fd-a7cc-03bdd082d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "futbol = pd.read_csv(\"FBRef2020-21.csv\")\n",
    "futbol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d01b9-ce74-4d21-a651-d432564660d2",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6b03e",
   "metadata": {},
   "source": [
    "Eliminamos los jugadores que jugaron menos de 500 minutos en la temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defff75-c1c3-4900-9f8b-90ec61a3849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "futbol = futbol[futbol['Min'] >= 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c797e80-c8fd-4b70-914f-0c12966a3659",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd824965",
   "metadata": {},
   "source": [
    "Ahora, eliminamos las columnas con más de 100 datos faltantes y eliminamos las filas con datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27f2ca-032e-4610-a6e8-2cd84020f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas con más de 100 datos faltantes\n",
    "futbol = futbol.loc[:, futbol.isnull().sum() <= 100]\n",
    "\n",
    "# Eliminar ahora las filas con datos faltantes\n",
    "futbol = futbol.dropna()\n",
    "\n",
    "futbol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96cb07-b8fe-4105-97d3-520bdae102eb",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd521d24",
   "metadata": {},
   "source": [
    "Reseteamos los índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655bded-de1e-4965-ae82-da486fba45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "futbol.reset_index(drop=True, inplace= True)\n",
    "futbol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8c815-e856-4e05-93c2-4dea05ccb1e4",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26f19a",
   "metadata": {},
   "source": [
    "Definimos el DataFrame data_num que solo contenga las variables númericas, a partir de la columna Ast/90, inclusive. A pedido del docente, para clustering y clasificación no vamos a utilizar las variables categóricas ni edad ni minutos jugados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f9b93-589d-48d1-9f37-61a5f287a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos DataFrame data_num\n",
    "\n",
    "# Seleccionamos el indice de la columna Ast/90\n",
    "indice_Ast90 = futbol.columns.get_loc('Ast/90')\n",
    "\n",
    "# Seleccionamos todas las columnas a partir de Ast/90 y luego nos quedamos solo con las que tienen datos numéricos\n",
    "data_num = futbol.iloc[:, indice_Ast90:].select_dtypes(include=[float, int])\n",
    "data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31bb62-6d49-4604-800b-57a46a12690e",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4dd084-6c3f-4080-920b-fd314141f69f",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6bc4b",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Seleccionar dos variables cualesquiera de los datos y realizar un gráfico de dispersión de una variable en función de la otra para el total de las observaciones\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(data=data_num, x=\"npG+A/90\", y=\"Shots/90\")\n",
    "    .add(so.Dot())\n",
    "    .layout(size=(10,6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b375ef8",
   "metadata": {},
   "source": [
    "En este grafico observamos sobre el eje X los goles + asistencias de los diferentes jugadores, y en el eje Y, los tiros al arco de los diferentes jugadores. Estas dos estadisticas están basadas en un promedio de cada 90 minutos. No encontramos facilmente grupos distintos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686f45f",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Escalar los datos y realizar un análisis de componentes principales, quedándose solo con las dos primeras componentes. Realizar un gráfico como el del punto ant\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos los datos\n",
    "data = StandardScaler().fit_transform(data_num)\n",
    "\n",
    "# Aplicamos PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "componentes = pca.fit_transform(data)\n",
    "pca_data_num = pd.DataFrame(data=componentes, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "pca_data_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc6e62",
   "metadata": {},
   "source": [
    "Ya realizado el análisis de componentes principales vamos a realizar el grafico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(data=pca_data_num, x=\"PC1\", y=\"PC2\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"PCA - Dos primeras componentes\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022e6e5",
   "metadata": {},
   "source": [
    "Observamos que podemos identificar principalmente dos clusters, uno muy grande que ocupa casi todo el grafico y uno muy chico que aparece en la parte baja del grafico. Si miramos más en detalle, podemos dividir el cluster grande en 2/3 clusters. Es decir, al final podemos visualizar hasta 4 clusters. A continuación vamos a crear estos clusters manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formo manualmente los clusters\n",
    "\n",
    "clusters = [\n",
    "    pca_data_num[\"PC2\"] < -8,\n",
    "    (pca_data_num[\"PC2\"] >= -8) & (pca_data_num[\"PC1\"] < -3),\n",
    "    (pca_data_num[\"PC1\"] >= -3) & (pca_data_num[\"PC1\"] <= 3),\n",
    "    pca_data_num[\"PC1\"] > 3\n",
    "]\n",
    "\n",
    "opc = [0, 1, 2, 3]\n",
    "\n",
    "# Asignar clusters basados en las condiciones\n",
    "pca_data_num[\"Cluster\"] = np.select(clusters, opc, default=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(data=pca_data_num, x=\"PC1\", y=\"PC2\", color = \"Cluster\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"PCA - Dos primeras componentes\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fce9a6",
   "metadata": {},
   "source": [
    "Vemos más claramente los clusters que mencionamos anteriormente. Ahora vamos a ver si podemos darnos cuenta a que características responden cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num['Cluster'] = pca_data_num['Cluster']\n",
    "cluster_analisis = data_num.groupby('Cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cad42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    so.Plot(data=cluster_analisis, x=\"npxG+xA/90\", y=\"Interceptions/90\", color='Cluster')\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Clusters basados en expectativa de goles y asistencias (cada 90 mins), y pases progresivos (cada 90 mins)\", x=\"Goles y asistencias esperados c/ 90 mins\", y=\"Intercepciones c/ 90 mins\")\n",
    "    .layout(size=(10, 8))\n",
    ")\n",
    "\n",
    "display(\n",
    "    so.Plot(data=cluster_analisis, x=\"Clearances/90\", y=\"SuccDrib/90\", color='Cluster')\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Clusters basados en despejes (cada 90 mins), y gambetas exitosas (cada 90 mins)\", x=\"Despejes c/ 90 mins\", y=\"Gambetas exitosas c/ 90 mins\")\n",
    "    .layout(size=(10, 8))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7424a8",
   "metadata": {},
   "source": [
    "### Grafico 1: \n",
    "Lo más seguro es que el cluster 0 pertenezca a los arqueros, ya que no cuenta ni con un alto numero de goles y asistencias esperadas cada 90 minutos, ni con un alto numero de intercepciones cada 90 minutos. Esto quiere decir que no defiende ni ataca, por lo que nos quedan los arqueros. El cluster 3 es bastante facil de reconocer tambien ya que al ser el cluster que más alto valor tiene en el eje x podemos asegurar que muy probablemente este sea el de los delanteros. Por último nos quedan los clusters 1 y 2. Creemos que el 1 es el de los defensores ya que cuenta con un mayor valor en el eje de intercepciones y menor en el eje de goles y asistencias. El último cluster (2) es el de muy probablemente los mediocampistas (están bastante arriba en el eje y, y casi en el medio del eje x).\n",
    "### Grafico 2:\n",
    "Podemos confirmar que el cluster 0 pertenece a los arqueros y el cluster 3 a los delanteros. También podemos decir que el cluster 2 pertenece a los mediocampistas ya que están bastante equilibrados en ambos graficos. Por último, el cluster 1 sería el de los defensores ya que siempre tienen un valor alto en el eje más defensivo.\n",
    "### Conclusión:\n",
    "El cluster 0 tiene caracteristicas muy pobres en estos graficos porque ahi se encuentran los arqueros.\n",
    "El cluster 1 tiene caracteristicas muy defensivas asique debe pertenecer a los defensores.\n",
    "El cluster 2 es el de características más equilibradas, por lo que debe pertenecer a los medios.\n",
    "Para concluir, el cluster 3 tiene características muy ofensivas (es decir pertenece a los delanteros)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a02b1",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Para la cantidad de clusters observados en el ítem anterior, realizar un agrupamiento por k-medias, y colorear los puntos según las etiquetas obtenidas. ¿Coinci\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892748d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la cantidad de clusters que buscamos\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "\n",
    "# Ajustamos el modelo.\n",
    "kmeans.fit(pca_data_num[[\"PC1\",\"PC2\"]])\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Añadimos los labels al dataframe\n",
    "pca_data_num[\"Cluster\"] = labels\n",
    "\n",
    "(\n",
    "    so.Plot(data=pca_data_num, x=\"PC1\", y=\"PC2\", color=\"Cluster\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Gráfico de Dispersión de las dos Primeras Componentes Principales con Clusters\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430895bd",
   "metadata": {},
   "source": [
    "Luego de realizar un agrupamiento por k-medias, vemos que el resultado no es el que habiamos analizado anteriormente. Vemos que hay cuatro clusters pero no son los que vimos. Esto se debe a que el metodo de agrupamiento por k-medias consiste en encontrar centros para \"k\" clusters, y por lo tanto era esperable que los datos sean divididos de igual manera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67d648",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Repetir el agrupamiento utilizando DBSCAN. ¿Cómo eligirían en este caso un valor de ε apropiado\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e2eaf",
   "metadata": {},
   "source": [
    "Antes de realizar el agrupamiento por DBSCAN debemos encontrar el mejor parametro para eps (distancia entre puntos). Para esto vamos a realizar el siguiente metodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponemos \"n_neighbors=2\" ya que cada punto se incluye a si mismo en la busqueda del más cercano.\n",
    "cercanos = NearestNeighbors(n_neighbors=2)\n",
    "cercanos = cercanos.fit(pca_data_num[[\"PC1\",\"PC2\"]])\n",
    "\n",
    "distances, indices = cercanos.kneighbors(pca_data_num[[\"PC1\",\"PC2\"]])\n",
    "\n",
    "# Ignoramos la primer distancia que es la que tiene el punto con él mismo.\n",
    "distances = distances[:,1]\n",
    "\n",
    "# Ordenamos en orden ascendente.\n",
    "distances = np.sort(distances, axis=0)\n",
    "\n",
    "(\n",
    "    so.Plot(x = np.arange(len(distances)), y = distances)\n",
    "    .add(so.Line())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29777f55",
   "metadata": {},
   "source": [
    "Sabemos que el mejor valor es cuando se lleva a cabo la curva fuerte, es decir en aproximadamente 0.7. Procedemos a realizar el codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos un valor para minimo de puntos bastante alto. Luego vamos a elegir uno más chico y comparamos.\n",
    "dbscan = DBSCAN(eps=0.7, min_samples=25)\n",
    "dbscan.fit(pca_data_num[[\"PC1\",\"PC2\"]])\n",
    "labels = dbscan.labels_\n",
    "\n",
    "pca_data_num[\"Cluster\"] = labels\n",
    "\n",
    "(\n",
    "    so.Plot(data=pca_data_num, x=\"PC1\", y=\"PC2\", color=\"Cluster\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Gráfico de Dispersión de las dos Primeras Componentes Principales con Clusters\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478164f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El numero de clusters obtenidos con min_samples= 25 es: {pca_data_num['Cluster'].max()+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54345bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.7, min_samples=5)\n",
    "dbscan.fit(pca_data_num[[\"PC1\",\"PC2\"]])\n",
    "labels = dbscan.labels_\n",
    "\n",
    "pca_data_num[\"Cluster\"] = labels\n",
    "\n",
    "(\n",
    "    so.Plot(data=pca_data_num, x=\"PC1\", y=\"PC2\", color=\"Cluster\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Gráfico de dispersión de las dos primeras Componentes Principales con clusters\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El numero de clusters obtenidos con min_samples= 5 es: {pca_data_num['Cluster'].max()+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d41dd",
   "metadata": {},
   "source": [
    "Sacamos algunas conclusiones. En primer lugar, vemos que en ningun caso nos quedan los cuatro clusters que nos imaginabamos al principio. Luego, vemos que al usar un valor alto de puntos minimos, tenemos menor cantidad de clusters (6), y si usamos un valor más bajo tenemos una mayor cantidad de clusters (8), pero la diferencia es notablemente baja. Esto es algo esperado ya que al ver el grafico observamos que los puntos están sumamente cerca por lo que la cantidad minima de puntos no es algo que afecte demasiado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c506a",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Aplicar DBSCAN para realizar agrupamiento utilizando como datos todas las variables originales en vez de solo las dos componentes principales, modificando los v\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95b2ea",
   "metadata": {},
   "source": [
    "Lo que entendí de este ejercicio es que tengo que buscar el hiperparametro epsilon pero ahora ajustando con todos los componentes principales y no solo con los 2 primeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = StandardScaler().fit_transform(data_num)\n",
    "\n",
    "# Aplicamos PCA\n",
    "pca = PCA()\n",
    "\n",
    "componentes = pca.fit_transform(data2)\n",
    "pca_data_num2 = pd.DataFrame(data=componentes)\n",
    "\n",
    "for i, col in enumerate(pca_data_num2.columns):\n",
    "    pca_data_num2.rename(columns={col: f\"PC{i}\"}, inplace=True)\n",
    "\n",
    "pca_data_num2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbe2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cercanos = NearestNeighbors(n_neighbors=2)\n",
    "\n",
    "cercanos = cercanos.fit(pca_data_num2[pca_data_num2.columns])\n",
    "\n",
    "distances, indices = cercanos.kneighbors(pca_data_num2[pca_data_num2.columns])\n",
    "\n",
    "distances = distances[:,1]\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "\n",
    "(\n",
    "    so.Plot(x = np.arange(len(distances)), y = distances)\n",
    "    .add(so.Line())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c5f526",
   "metadata": {},
   "source": [
    "Usamos hiperparametro = 3 y luego hiperparametro = 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=3, min_samples=5)\n",
    "dbscan.fit(pca_data_num2[pca_data_num2.columns])\n",
    "labels = dbscan.labels_\n",
    "\n",
    "pca_data_num2[\"Cluster\"] = labels\n",
    "\n",
    "(\n",
    "    so.Plot(data=pca_data_num2, x=\"PC1\", y=\"PC2\", color=\"Cluster\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Gráfico de dispersión con todas las Componentes Principales con clusters\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El numero de clusters obtenidos con min_samples= 5 es: {pca_data_num2['Cluster'].max()+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=9, min_samples=15)\n",
    "dbscan.fit(pca_data_num2[pca_data_num2.columns])\n",
    "labels = dbscan.labels_\n",
    "\n",
    "pca_data_num2[\"Cluster\"] = labels\n",
    "\n",
    "(\n",
    "    so.Plot(data=pca_data_num2, x=\"PC1\", y=\"PC2\", color=\"Cluster\")\n",
    "    .add(so.Dot())\n",
    "    .label(title=\"Gráfico de dispersión con todas las Componentes Principales con clusters\")\n",
    "    .layout(size=(10,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El numero de clusters obtenidos con min_samples= 5 es: {pca_data_num2['Cluster'].max()+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf89289",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "anterior.\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586b5f7-ec12-45d7-8698-ffec3d36cb76",
   "metadata": {},
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a7467-ab63-4c23-ab61-d69fadb76715",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139fd354",
   "metadata": {},
   "source": [
    "Ahora queremos poder predecir la posición en la que juega cada jugador según sus datos estadísticos utilizando KNN. En la columna Pos encontramos la posición de los jugadores. Para la mayoría de los jugadores se indica una única posición pero algunos jugadores tienen dos posiciones. Para simplificar el análisis vamos a considerar una única posición por jugador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12019e1b",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Definir la variable Pos_filt que es la columna Pos, pero donde los jugadores deben tener una sola posición (pueden quedarse sólo con la primera posición de cada\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8704c-0f93-4500-9570-1c62e62d8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la variable Pos_filt que son los datos de la columna Pos pero cada jugador tiene solo una posición.\n",
    "futbol['Pos_filt'] = futbol['Pos'].str.split(',').str[0] #dividimos la cadena de posiciones que estan separadas (de haber 2) por una coma y nos quedamos solo con la primera de las Pos.\n",
    "futbol[['Player','Pos','Pos_filt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34c627-4c3f-4584-8c03-8ccfd6240b7f",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Dividir el DataFrame data_num y la Series Pos_filt utilizando un 80% para entrenamiento y un 20% para testeo.\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e65e15-2a90-4bc1-9b76-a940806fc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_num\n",
    "y = futbol['Pos_filt']\n",
    "X = MinMaxScaler().set_output(transform='pandas').fit_transform(X)\n",
    "#Separo el DataFrame data_num y la Serie Pos_filt en entrenamineto (80%) y testeo(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa916f6b-28b8-4ffc-b034-a863b49219de",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Aplicar un esquema de validación en el conjunto de entrenamiento para seleccionar el valor óptimo de K. (Esto puede demorar mucho si prueban muchos valores de K\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8a2dd-7a38-41ae-84e7-18fea0a3a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_k_scores = []\n",
    "for K in range(1,21): # probamos con K del 1 al 20\n",
    "    neighbor = KNeighborsClassifier(n_neighbors=K) \n",
    "    scores = cross_val_score(neighbor, X_train, y_train) #Hacemos validación cruzada con cada K en los conjuntos de entrenamiento.\n",
    "    cv_k_scores.append(scores.mean()) # Hace un promedio de los valores de score obtenidos en las particiones del cross validation.\n",
    "    print(K,scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68073d-d7e9-4e14-b3ce-776734e88c7f",
   "metadata": {},
   "source": [
    "Vemos que el K optimo es el K=8. Ahora vamos a chequear nuestra elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddbea8-490d-4b0a-9642-c1aab5d2c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_optimo = cv_k_scores.index(max(cv_k_scores)) + 1\n",
    "print(\"el K óptimo es K =\", K_optimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5840e-1d10-4ed1-a0fe-adb7e79e5020",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Para el valor de K obtenido, ¿cuál es el porcentaje de aciertos en el conjunto de testeo\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf84f9e-8603-4d40-8566-47d26bea05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo con el valor óptimo de K\n",
    "neighbor = KNeighborsClassifier(n_neighbors=K_optimo)\n",
    "neighbor.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = neighbor.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(\"Porcentaje de acierto en el conjunto de testeo: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3633277",
   "metadata": {},
   "source": [
    "### Recomendaciones de jugadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69667f02",
   "metadata": {},
   "source": [
    "#### 8) Trabajamos ahora con el dataset transfermarkt_fbref_201920.csv que incluye la valuación de los jugadores. Una de las aplicaciones más comunes de análisis de datos en el fútbol es para obtener recomendaciones de jugadores a comprar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c57467",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"transfermarkt_fbref_201920.csv\", delimiter=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0017e",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "En 2021 Messi fue transferido del Barcelona al PSG. Basándose en los datos disponibles, recomendarle a Barcelona un jugador de características similares a Messi\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa52b4b",
   "metadata": {},
   "source": [
    "Para encontrar jugadores con características parecidas a Messi vamos a utilizar PCA teniendo en cuenta solo las variables numericas. Luego de esos jugadores vamos a ver cual tiene un valor de mercado menor al de Messi y juega en una posición similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e92f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.set_index(\"player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d85991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos las columnas con valores no numericos\n",
    "X = data2.drop(columns=[\"nationality\",\"position\",\"squad\",\"position2\", \"foot\", \"league\",\"Season\"])\n",
    "\n",
    "# Le sacamos las comas a los numeros dado que sino nos provocaba un error al correr el codigo\n",
    "X = X.map(lambda x: float(str(x).replace(',', '')) if isinstance(x, str) else x)\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "# Aplicamos PCA ajustando a un 90%\n",
    "pca = PCA(n_components=0.90)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Creamos el nuevo dataframe\n",
    "data2_pca = pd.DataFrame(X_pca, index=data2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23151152",
   "metadata": {},
   "outputs": [],
   "source": [
    "jugadores_elegidos = []\n",
    "\n",
    "# Definimos los datos de Messi y el rango que le daremos al \"reemplazo\"\n",
    "stat_messi = data2_pca.loc[\"Lionel Messi\", 0]\n",
    "limite_inf = stat_messi * 0.75\n",
    "limite_sup = stat_messi * 1.25\n",
    "\n",
    "# Iteramos sobre cada jugador\n",
    "for jugador in data2_pca.index:\n",
    "        \n",
    "    if jugador == \"Lionel Messi\":\n",
    "        continue\n",
    "    \n",
    "    stats_cercanas_a_messi = 0\n",
    "\n",
    "    stat_jugador = data2_pca.loc[jugador, 0]\n",
    "    \n",
    "    \n",
    "    # Queremos solo los valores escalares\n",
    "    if not isinstance(stat_jugador, (int, float)):\n",
    "       continue\n",
    "    \n",
    "    # Verificamos el nuevo jugador entre en nuestros límites\n",
    "    if limite_inf <= stat_jugador <= limite_sup:\n",
    "        jugadores_elegidos.append(jugador)\n",
    "        \n",
    "        \n",
    "print(jugadores_elegidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709494d",
   "metadata": {},
   "source": [
    "Podemos ver que los jugadores que entran en nuestro rango son: Oblak, Griezmann, Sancho, Alexander-Arnold, Mané, Salah, De Bruyne, Sterling, Neymar y Kane. De estos, vamos a descartar a Oblak y Alexander-Arnold ya que son arquero y defensor respectivamente. Vamos a ver el valor de mercado de los demás y luego vamos a dar el elegido para ser el reemplazo de Lionel Messi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_messi = data2.loc[\"Lionel Messi\", \"value\"]\n",
    "\n",
    "jugadores = []\n",
    "\n",
    "for jugador in [\"Antoine Griezmann\",\"Jadon Sancho\",\"Sadio Mané\",\"Mohamed Salah\",\"Kevin De Bruyne\",\"Harry Kane\",\"Raheem Sterling\",\"Neymar\"]:\n",
    "    valor_jugador = data2.loc[jugador, \"value\"]\n",
    "    if valor_jugador < valor_messi:\n",
    "        jugadores.append(jugador)\n",
    "\n",
    "print(jugadores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8156f77",
   "metadata": {},
   "source": [
    "Luego de finalizar el análisis, podemos decir que el reemplazo de Messi debe ser Antoine Griezmann, ya que es el único jugador que cumplió con todos los requisitos solicitados, y además juega en la misma posición que Lionel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb0e1d",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Queremos elaborar un modelo para detectar jugadores “baratos”, es decir cuya valuación en el mercado (columna value) sea inferior a que la que nosotros estimemo\n",
    "\n",
    "### Enfoque\n",
    "Se implementa el procedimiento descrito, documentando las decisiones de preprocesamiento y validando los resultados con visualizaciones y métricas cuando corresponde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8855046",
   "metadata": {},
   "source": [
    "Intentaremos hacer redes neuronales..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6680b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "\n",
    "columnas = [\"nationality\",\"position\",\"squad\",\"position2\", \"foot\", \"league\"]\n",
    "\n",
    "for col in columnas:\n",
    "    data2[col + \"_nueva\"] = label.fit_transform(data2[col])\n",
    "    data2.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a80f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2.drop([\"value\",\"Season\"],axis=1)\n",
    "y = data2[\"value\"]\n",
    "\n",
    "# Le saco las comas\n",
    "X = X.map(lambda x: float(str(x).replace(',', '')) if isinstance(x, str) else x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e28993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "modelo = model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "hist = model.fit(X_train.to_numpy(), y_train.to_numpy(), epochs=50, batch_size=32, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb850f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"El error cuadratico medio es de: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d078f7b",
   "metadata": {},
   "source": [
    "Vemos que no quedó muy bien asique probamos con regresión Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dcdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(jugador):\n",
    "    X = data2.drop([\"value\",\"Season\"],axis=1)\n",
    "    y = data2[\"value\"]\n",
    "\n",
    "    X = X.map(lambda x: float(str(x).replace(',', '')) if isinstance(x, str) else x)\n",
    "    X = X.dropna(axis=1)\n",
    "\n",
    "    alphas = [1,10,100,500,1000,2000,5000,7000,10000,20000,50000]\n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "    error_cuadratico_medio = float('inf')\n",
    "\n",
    "    for alpha in alphas:\n",
    "        modelo = linear_model.Ridge(alpha = alpha, fit_intercept = False)    \n",
    "        rmse = np.zeros(cv.get_n_splits())\n",
    "\n",
    "        ind = 0\n",
    "    \n",
    "        for train_index, val_index in cv.split(X):\n",
    "            X_train, X_val, y_train, y_val = X.iloc[train_index], X.iloc[val_index], y.iloc[train_index], y.iloc[val_index]\n",
    "            modelo.fit(X_train, y_train)\n",
    "    \n",
    "            y_pred_val = modelo.predict(X_val)\n",
    "            rmse[ind] = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "            ind += 1\n",
    "    \n",
    "        if rmse.mean() < error_cuadratico_medio:\n",
    "            error_cuadratico_medio = rmse.mean()\n",
    "            alpha_optimo = alpha\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    modelo = linear_model.Ridge(alpha = alpha_optimo, fit_intercept = False)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    valor = data2.loc[jugador,\"value\"]\n",
    "    \n",
    "    return print(f\"El valor de {jugador} en el mercado es de {valor}$ y nuestra predicción fue de {valor + rmse:.0f}$\")\n",
    "\n",
    "print(predecir(\"Lionel Messi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43453d78",
   "metadata": {},
   "source": [
    "## Resultados principales (resumen)\n",
    "\n",
    "- **Clustering**: se identifican perfiles de jugadores con patrones diferenciados en el espacio de características.\n",
    "- **Clasificación**: se entrena un modelo para predecir posición/rol utilizando validación cruzada y métricas estándar.\n",
    "- **Recomendación**: se propone un ranking de jugadores similares incorporando criterios de rendimiento y costo.\n",
    "- **Valuación**: se estima valor de mercado aproximado a partir de variables predictoras relevantes.\n",
    "\n",
    "> Completar con métricas/números concretos (accuracy/RMSE/ejemplos) una vez fijada la configuración final.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
